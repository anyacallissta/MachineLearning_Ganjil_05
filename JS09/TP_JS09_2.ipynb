{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYOJYZP7pJ-U"
      },
      "source": [
        "# JS09 - TUGAS 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xli_W5g2Exn0",
        "outputId": "7cfbf892-0fb1-44d9-e5b4-ba232382026c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===================================================\n",
            "   COUNT VECTORIZER + MULTINOMIAL NB\n",
            "===================================================\n",
            "Accuracy: 0.9802690582959641\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.99      0.99       965\n",
            "        spam       0.93      0.93      0.93       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.96      0.96      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "===================================================\n",
            "      TF-IDF + MULTINOMIAL NB\n",
            "===================================================\n",
            "Accuracy: 0.968609865470852\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98       965\n",
            "        spam       1.00      0.77      0.87       150\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.93      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n",
            "===================================================\n",
            "                 PERBANDINGAN AKURASI\n",
            "===================================================\n",
            "CountVectorizer Accuracy : 0.9802690582959641\n",
            "TF-IDF Accuracy          : 0.968609865470852\n",
            "\n",
            "Kesimpulan: CountVectorizer adalah fitur terbaik untuk kasus spam.csv\n"
          ]
        }
      ],
      "source": [
        "# LOAD DATA\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "file_id = \"1ebBtW6kQiBgtQ4qbrzEeq45d6iZuPRGR\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "df = pd.read_csv(url, encoding='latin-1')\n",
        "df.head()\n",
        "\n",
        "# Biasanya spam.csv memiliki kolom ekstra tak digunakan\n",
        "df = df.rename(columns={df.columns[0]: \"label\", df.columns[1]: \"text\"})\n",
        "df = df[[\"label\", \"text\"]]\n",
        "\n",
        "X = df[\"text\"]\n",
        "y = df[\"label\"]\n",
        "\n",
        "# COUNT VECTORIZER + STOP WORDS\n",
        "cv = CountVectorizer(stop_words=\"english\")\n",
        "X_cv = cv.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_cv, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model_cv = MultinomialNB()\n",
        "model_cv.fit(X_train, y_train)\n",
        "pred_cv = model_cv.predict(X_test)\n",
        "\n",
        "acc_cv = accuracy_score(y_test, pred_cv)\n",
        "report_cv = classification_report(y_test, pred_cv)\n",
        "\n",
        "print(\"===================================================\")\n",
        "print(\"   COUNT VECTORIZER + MULTINOMIAL NB\")\n",
        "print(\"===================================================\")\n",
        "print(\"Accuracy:\", acc_cv)\n",
        "print(report_cv)\n",
        "\n",
        "\n",
        "# TF-IDF + STOP WORDS\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
        "X_tfidf = tfidf.fit_transform(X)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
        "    X_tfidf, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model_tfidf = MultinomialNB()\n",
        "model_tfidf.fit(X_train2, y_train2)\n",
        "pred_tfidf = model_tfidf.predict(X_test2)\n",
        "\n",
        "acc_tfidf = accuracy_score(y_test2, pred_tfidf)\n",
        "report_tfidf = classification_report(y_test2, pred_tfidf)\n",
        "\n",
        "print(\"===================================================\")\n",
        "print(\"      TF-IDF + MULTINOMIAL NB\")\n",
        "print(\"===================================================\")\n",
        "print(\"Accuracy:\", acc_tfidf)\n",
        "print(report_tfidf)\n",
        "\n",
        "\n",
        "# PERBANDINGAN & KESIMPULAN\n",
        "print(\"===================================================\")\n",
        "print(\"                 PERBANDINGAN AKURASI\")\n",
        "print(\"===================================================\")\n",
        "print(\"CountVectorizer Accuracy :\", acc_cv)\n",
        "print(\"TF-IDF Accuracy          :\", acc_tfidf)\n",
        "\n",
        "if acc_tfidf > acc_cv:\n",
        "    print(\"\\nKesimpulan: TF-IDF adalah fitur terbaik untuk kasus spam.csv\")\n",
        "else:\n",
        "    print(\"\\nKesimpulan: CountVectorizer adalah fitur terbaik untuk kasus spam.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
